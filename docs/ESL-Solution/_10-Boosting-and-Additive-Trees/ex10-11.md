---
title: Ex. 10.11
linktitle: Ex 10.11
type: book
date: "2021-01-02T00:00:00+01:00"
# Prev/next pager order (if `docs_section_pager` enabled in `params.toml`)
weight: 1
toc: false
---

???+ question "Ex. 10.11"
    Show how to compute the partial dependence function $f_{\mathcal{S}}(X_{\mathcal{S}})$ in (10.47) efficiently.

??? done "Soln. 10.11"
    In general, to calculate partial dependence as in (10.47), given a $x_s\in X_{\mathcal{S}}$, we need to make $N$ predictions for $N$ samples $(x_s, x_{i\mathcal{C}}) (i=1,...,N)$ and take an average.
	
	For decision trees, note that each node of the fitted tree remembers how many training samples went through it during the training, and thus we can use associated ratios to derive the final average. That means, we only need to traverse the tree for once. Please see [Efficient Partial Dependence Plots with decision trees](http://nicolas-hug.com/blog/pdps) for a detailed description and scikit-learn's [implementation](https://github.com/scikit-learn/scikit-learn/blob/ff6f880755d12a380dbdac99f6b9d169aee8b588/sklearn/ensemble/_hist_gradient_boosting/_predictor.pyx#L99).